{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e5896607",
   "metadata": {},
   "source": [
    "# Belfius Alytics (Part 2)\n",
    "Inspiration:\n",
    "\n",
    "-https://github.com/pinecone-io/examples/blob/master/learn/generation/langchain/handbook/08-langchain-retrieval-agent.ipynb\n",
    "-https://www.youtube.com/watch?v=RIWbalZ7sTo\n",
    "-https://colab.research.google.com/drive/13FpBqmhYa5Ex4smVhivfEhk2k4S5skwG?usp=sharing#scrollTo=RSdomqrHNCUY"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51e3d0bf",
   "metadata": {},
   "source": [
    "### Handle imports:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7fc991da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\MD726YR\\PycharmProjects\\eyalytics\n"
     ]
    }
   ],
   "source": [
    "# Move to root directory\n",
    "import os\n",
    "\n",
    "notebooks_dir = 'notebooks'\n",
    "if notebooks_dir in os.path.abspath(os.curdir):\n",
    "    while not os.path.abspath(os.curdir).endswith('notebooks'):\n",
    "        print(os.path.abspath(os.curdir))\n",
    "        os.chdir('..')\n",
    "    os.chdir('..')  # to get to root\n",
    "\n",
    "print(os.path.abspath(os.curdir))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ee1a528e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Supress SSL verification (EY problem):\n",
    "import requests\n",
    "\n",
    "from requests.packages.urllib3.exceptions import InsecureRequestWarning\n",
    "\n",
    "# Suppress the warning from urllib3.\n",
    "requests.packages.urllib3.disable_warnings(category=InsecureRequestWarning)\n",
    "\n",
    "old_send = requests.Session.send\n",
    "\n",
    "def new_send(*args, **kwargs):\n",
    "    kwargs['verify'] = False\n",
    "    return old_send(*args, **kwargs)\n",
    "\n",
    "requests.Session.send = new_send"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e4382367",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import relevant libraries for langchain retrieval:\n",
    "import tiktoken\n",
    "\n",
    "from langchain import OpenAI,  LLMChain, PromptTemplate\n",
    "from langchain.prompts import StringPromptTemplate\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain.embeddings.openai import OpenAIEmbeddings\n",
    "from langchain.vectorstores import FAISS  # facebook ai similarity search \n",
    "from langchain.chains import LLMMathChain\n",
    "from langchain.tools import BaseTool\n",
    "from langchain.agents import (\n",
    "    AgentExecutor, LLMSingleActionAgent, AgentOutputParser, \n",
    "    AgentType, initialize_agent, Tool\n",
    ")\n",
    "from langchain.callbacks import get_openai_callback\n",
    "from langchain.schema import AgentAction, AgentFinish"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0db1aa2",
   "metadata": {},
   "source": [
    "**In case you want to use Chroma instead of FAISS:**\n",
    "\n",
    "`from langchain.vectorstores import Chroma`\n",
    "    \n",
    "Note, to use Chroma you will have to install chromadb. This requires having Microsoft Visual C++ 14.0 installed. To install that simply: \n",
    "\n",
    "a. Install Microsoft C++ Build Tools: Visit the link provided in the error message (https://visualstudio.microsoft.com/visual-cpp-build-tools/) and install the Microsoft C++ Build Tools.\n",
    "\n",
    "b. Ensure the Correct Version: Ensure that you have the required version (14.0 or greater) of the C++ build tools installed.\n",
    "\n",
    "c. Add to PATH: Ensure the tools are added to your system PATH. Usually, the installer should take care of this. But if the problem persists, you might need to verify and add them manually.\n",
    "\n",
    "d. Restart Your System: Sometimes, after installing such tools, a system restart might be required for the environment variables (like PATH) to update correctly.\n",
    "\n",
    "**Checks:**\n",
    "Check if Visual C++ Build Tools is Installed:\n",
    "- Press Windows + I to open the Settings app.\n",
    "- Go to \"Apps\".\n",
    "- Now in the \"Apps & features\" tab, search for \"Visual Studio\".\n",
    "- Check if there's an installation called \"Microsoft Visual Studio\" (it might also be \"Visual Studio Build Tools\").\n",
    "\n",
    "Check for the Required Components:\n",
    "- If you find \"Microsoft Visual Studio\" or \"Visual Studio Build Tools\" in the list, click on it and then select \"Modify\".\n",
    "- This will bring up the Visual Studio Installer.\n",
    "- Here, ensure that the \"Desktop development with C++\" workload is checked. Specifically, make sure \"MSVC v142 - VS 2019 C++ x64/x86 build tools\" (or a similar option) is selected. This provides the C++ compiler that's needed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a6c4cc3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# libraries for URL pdf loading\n",
    "from io import BytesIO, StringIO\n",
    "from pdfminer.layout import LAParams\n",
    "from pdfminer.high_level import extract_text, extract_text_to_fp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "49c362c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Other libraries:\n",
    "import re\n",
    "import pickle \n",
    "import difflib\n",
    "\n",
    "# for progress bars in loops\n",
    "from uuid import uuid4\n",
    "from tqdm.auto import tqdm\n",
    "from typing import List, Any, Union, Optional"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5355980c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get API and ENV keys:\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "if not os.getenv(\"OPENAI_API_KEY\"):\n",
    "    raise KeyError(\n",
    "        \"You will need an OPENAI_API_KEY to use the LLM models in this notebook.\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb02be3b",
   "metadata": {},
   "source": [
    "## Commence Langchain Retrieval Augmentation Tool Development:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "979fd477",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create URL loader:\n",
    "def get_pdf_content_from_url(url: str, page_start: int = 0, n_pages: int = None) -> str:\n",
    "    try:\n",
    "        # Fetch the PDF content using requests\n",
    "        response = requests.get(url)\n",
    "        response.raise_for_status()  # Raises an HTTPError if the response returned an unsuccessful status code\n",
    "\n",
    "        # If n_pages is not specified, read till the end\n",
    "        end_page = page_start + n_pages if n_pages is not None else None\n",
    "\n",
    "        # Use BytesIO to convert the byte stream to a file-like object so it can be read by pdfminer\n",
    "        with BytesIO(response.content) as pdf_data, StringIO() as output_string:\n",
    "            # Extract text from the PDF for the specified pages\n",
    "            extract_text_to_fp(\n",
    "                pdf_data, output_string, laparams=LAParams(), \n",
    "                page_numbers=list(range(page_start, end_page or int(1e9)))\n",
    "            )  # use a large number as default if end_page is None\n",
    "            return output_string.getvalue()\n",
    "    except requests.RequestException as e:\n",
    "        print(f\"Error fetching the PDF: {e}\")\n",
    "        return \"\"\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing the PDF: {e}\")\n",
    "        return \"\"\n",
    "\n",
    "# URL -> file name convertor:\n",
    "def url2fname(url):\n",
    "    # Split the URL by '/' and get the last segment\n",
    "    last_segment = url.split('/')[-1]\n",
    "    \n",
    "    # Use regex to remove any suffix after the dot and the dot itself\n",
    "    cleaned_name = re.sub(r'\\..*$', '', last_segment)\n",
    "    \n",
    "    return cleaned_name\n",
    "    \n",
    "# Testing the function\n",
    "url = \"https://www.coca-colacompany.com/content/dam/company/us/en/reports/coca-cola-business-and-sustainability-report-2022.pdf\"\n",
    "fname = url2fname(url)  # used to save vectordb\n",
    "text = get_pdf_content_from_url(url, page_start=13, n_pages=9)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b69ddc51",
   "metadata": {},
   "source": [
    "### Text Splitting, Embedding Models, and Vector DB\n",
    "\n",
    "We'll be using OpenAI's text-embedding-ada-002 model and Pinecone's FREE vector DB. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "769b9822",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = 'gpt-3.5-turbo'  # open ai LLM model we will be using later.\n",
    "model = 'text-davinci-003'  # open ai LLM model we will be using later.\n",
    "enc_code = tiktoken.encoding_for_model(model).name\n",
    "tokenizer = tiktoken.get_encoding(enc_code)\n",
    "\n",
    "# Determine length of input after tokenization\n",
    "def tiktoken_len(text):\n",
    "    tokens = tokenizer.encode(\n",
    "        text,\n",
    "        disallowed_special=()\n",
    "    )\n",
    "    return len(tokens)\n",
    "\n",
    "text_splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size=600,  # in order to be able to fit 3 chunks in context window\n",
    "    chunk_overlap=100,  \n",
    "    length_function=tiktoken_len,\n",
    "    separators=[\"\\n\\n\", \"\\n\", \" \", \"\"]  # order in which splits are prioritized\n",
    ")\n",
    "chunks = text_splitter.split_text(text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7558e017",
   "metadata": {},
   "source": [
    "### Indexing:\n",
    "Store the indexes to avoid pointlessly rerunning the embedding code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "322dc78e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The loaded document has 28121 characters.\n",
      "Meaning that to embed the document using text-embedding-ada-002 will cost roughly $0.00028121.\n"
     ]
    }
   ],
   "source": [
    "print(\n",
    "    f\"The loaded document has {len(text)} characters.\\n\"\n",
    "    f\"Meaning that to embed the document using text-embedding-ada-002 \"\n",
    "    f\"will cost roughly ${(len(text) / 1000) * 0.00001}.\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b5b4c2f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "fpath = f\"./data/faiss_db/{fname}.pkl\"\n",
    "if os.path.exists(fpath):\n",
    "    with open(fpath, 'rb') as f:\n",
    "        vector_store = pickle.load(f)\n",
    "else:\n",
    "    # Init embedding model:\n",
    "    embed = OpenAIEmbeddings(\n",
    "        model='text-embedding-ada-002'\n",
    "    )\n",
    "    vector_store = FAISS.from_texts(chunks, embedding=embed)\n",
    "    with open(fpath, 'wb') as f:\n",
    "        pickle.dump(vector_store, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e74ce087",
   "metadata": {},
   "source": [
    "### Set up QA Agent:\n",
    "We will create an agent cabale of:\n",
    "- Fetching contextual information from the vector store\n",
    "- Performing basic math operations \n",
    "The thought being that this way the agent may be able to compute KPIs which require basic math operations to compute."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a6de6418",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = OpenAI(\n",
    "    temperature=0,\n",
    "    model_name=model\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "952f1a5a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n",
      "The information was shared in the previous information_retrival calls.\n"
     ]
    }
   ],
   "source": [
    "import difflib\n",
    "\n",
    "class ContextRetrieval(object):\n",
    "    name = \"information_retrival\"\n",
    "    description = \"\"\"\n",
    "        Fetch the most recent information about a company's financials and ESG initiatives.\n",
    "    \"\"\"\n",
    "    \n",
    "    output_chunks = []\n",
    "\n",
    "    @staticmethod\n",
    "    def string_similarity(s1, s2):\n",
    "        seq_matcher = difflib.SequenceMatcher(None, s1, s2)\n",
    "        return seq_matcher.ratio()\n",
    "\n",
    "    def _similarity_search(self, chunk: str) -> str:\n",
    "        for _chunk in self.output_chunks:\n",
    "            if self.string_similarity(chunk, _chunk) > 0.9:\n",
    "                return f\"The information was shared in the previous {self.name} calls.\"\n",
    "        \n",
    "        # If no highly similar string is found in the outputs, \n",
    "        # append the query to outputs and return True\n",
    "        self.output_chunks.append(chunk)\n",
    "        return\n",
    "\n",
    "# Test\n",
    "context = ContextRetrieval()\n",
    "\n",
    "test_string1 = \"Apple is a company that produces tech products.\"\n",
    "test_string2 = \"Apple iss a company that produces tech productsss.\"\n",
    "\n",
    "print(context._similarity_search(test_string1))  # True\n",
    "print(context._similarity_search(test_string2))  # \"The information was shared previously\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "55fa7152",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ContextRetrieval(BaseTool):\n",
    "    \n",
    "    name = \"information_retrival\"\n",
    "    description = \"\"\"\n",
    "        Fetch the most recent information about a company's financials and ESG initiatives.\n",
    "    \"\"\"\n",
    "    output_chunks = []\n",
    "\n",
    "    @staticmethod\n",
    "    def string_similarity(s1, s2):\n",
    "        seq_matcher = difflib.SequenceMatcher(None, s1, s2)\n",
    "        return seq_matcher.ratio()\n",
    "\n",
    "    def _similarity_search(self, chunk: str) -> str:\n",
    "        for _chunk in self.output_chunks:\n",
    "            if self.string_similarity(chunk, _chunk) > 0.9:\n",
    "                return f\"The information was shared in the previous {self.name} calls.\"\n",
    "        \n",
    "        # If no highly similar string is found in the outputs, \n",
    "        # append the query to outputs and return True\n",
    "        self.output_chunks.append(chunk)\n",
    "        return chunk\n",
    "    \n",
    "    def _run(self, query: str) -> str:\n",
    "        contents = [\n",
    "            self._similarity_search(doc.page_content) \n",
    "            for doc in vector_store.similarity_search(query, k=2)\n",
    "        ]\n",
    "        \n",
    "        full_content = '\\n\\n'.join(\n",
    "            [\n",
    "                f\"Rank: {rank} | Content: {_content}\" \n",
    "                for rank, _content in enumerate(contents, start=1)\n",
    "            ]\n",
    "        )\n",
    "        return full_content + \"\\n\\nContextual information sorted from most relevant to least relevant.\"\n",
    "    \n",
    "    def _arun(self, query: str):\n",
    "        raise NotImplementedError(\n",
    "            f\"{self.__class__.__name__} does not currently support async run.\"\n",
    "        )\n",
    "        \n",
    "llm_math = LLMMathChain(llm=llm)\n",
    "\n",
    "# initialize the math tool\n",
    "math_tool = Tool(\n",
    "    name='Calculator',\n",
    "    func=llm_math.run,\n",
    "    description='Useful when you need to perform math operations.'\n",
    ")\n",
    "# when giving tools to an LLM, we must pass them as a list of tools.\n",
    "tools = [math_tool, ContextRetrieval()]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "948f0e93",
   "metadata": {},
   "source": [
    "**Setup an agent just like in url_retrieval.ipynb.**\n",
    "\n",
    "Note that a `utils.py` file will be created to store these in the future."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "490cf41e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up the base template\n",
    "template = \"\"\"You are an analyst tasked with aggregating financial and ESG KPIs about companies. You have access to the following tools:\n",
    "\n",
    "{tools}\n",
    "\n",
    "Use the following format:\n",
    "\n",
    "Question: the input question you must answer\n",
    "Thought: you should always think about what to do\n",
    "Action: the action to take, should be one of [{tool_names}]\n",
    "Action Input: the input to the action\n",
    "Observation: the result of the action\n",
    "... (this Thought/Action/Action Input/Observation can repeat N times)\n",
    "Thought: I now know the final answer\n",
    "Final Answer: the final answer to the original input question\n",
    "\n",
    "Begin! Remember to answer as succinctly as possible when giving your final answer. The final answer, where possible, should just be a number or a boolean.\n",
    "\n",
    "Question: {input}\n",
    "{agent_scratchpad}\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "90d4959d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up a prompt template which breaksup the intermediate_steps\n",
    "# into thoughts that are used to fill the agent_scratchpad, \n",
    "# tools, and tool_names in the base template:\n",
    "class CustomPromptTemplate(StringPromptTemplate):\n",
    "    # The template to use\n",
    "    template: str\n",
    "    # The list of tools available\n",
    "    tools: List[BaseTool or Tool]\n",
    "    \n",
    "    def format(self, **kwargs) -> str:\n",
    "        # Get the intermediate steps (AgentAction, Observation tuples)\n",
    "        # Format them in a particular way\n",
    "        intermediate_steps = kwargs.pop(\"intermediate_steps\")\n",
    "        thoughts = \"\"\n",
    "        for action, observation in intermediate_steps:\n",
    "            thoughts += action.log\n",
    "            thoughts += f\"\\nObservation: {observation}\\nThought: \"\n",
    "        # Set the agent_scratchpad variable to that value\n",
    "        kwargs[\"agent_scratchpad\"] = thoughts\n",
    "        # Create a tools variable from the list of tools provided\n",
    "        kwargs[\"tools\"] = \"\\n\".join([f\"{tool.name}: {tool.description}\" for tool in self.tools])\n",
    "        # Create a list of tool names for the tools provided\n",
    "        kwargs[\"tool_names\"] = \", \".join([tool.name for tool in self.tools])\n",
    "        return self.template.format(**kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "d438d400",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = CustomPromptTemplate(\n",
    "    template=template,\n",
    "    tools=tools,\n",
    "    # This omits the `agent_scratchpad`, `tools`, and `tool_names` variables because those are generated dynamically\n",
    "    # This includes the `intermediate_steps` variable because that is needed\n",
    "    input_variables=[\"input\", \"intermediate_steps\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "1f16cfdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomOutputParser(AgentOutputParser):\n",
    "    \n",
    "    def parse(self, llm_output: str) -> Union[AgentAction, AgentFinish]:\n",
    "        # Check if agent should finish\n",
    "        if \"Final Answer:\" in llm_output:\n",
    "            return AgentFinish(\n",
    "                # Return values is generally always a dictionary with a single `output` key\n",
    "                # It is not recommended to try anything else at the moment :)\n",
    "                return_values={\"output\": llm_output.split(\"Final Answer:\")[-1].strip()},\n",
    "                log=llm_output,\n",
    "            )\n",
    "        # Parse out the action and action input\n",
    "        regex = r\"Action\\s*\\d*\\s*:(.*?)\\nAction\\s*\\d*\\s*Input\\s*\\d*\\s*:[\\s]*(.*)\"\n",
    "        match = re.search(regex, llm_output, re.DOTALL)\n",
    "        if not match:\n",
    "            raise ValueError(f\"Could not parse LLM output: `{llm_output}`\")\n",
    "        action = match.group(1).strip()\n",
    "        action_input = match.group(2)\n",
    "        # Return the action and action input\n",
    "        return AgentAction(tool=action, tool_input=action_input.strip(\" \").strip('\"'), log=llm_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "cd3cface",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = OpenAI(\n",
    "    temperature=0,  # measure of randomness/creativity\n",
    "    model_name=model\n",
    ")\n",
    "\n",
    "# LLM chain consisting of the LLM and a prompt\n",
    "llm_chain = LLMChain(\n",
    "    llm=llm, \n",
    "    prompt=prompt  # Custom Prompt\n",
    ")\n",
    "\n",
    "tool_names = [tool.name for tool in tools]\n",
    "\n",
    "agent = LLMSingleActionAgent(\n",
    "    llm_chain=llm_chain, \n",
    "    output_parser=CustomOutputParser(),\n",
    "    stop=[\"\\nObservation:\"],  # you want this to be whatever token you use in the prompt to denote the start of an Observation\n",
    "    allowed_tools=tool_names\n",
    ") \n",
    "\n",
    "agent_executor = AgentExecutor.from_agent_and_tools(\n",
    "    agent=agent, \n",
    "    tools=tools, \n",
    "    verbose=True,\n",
    "    max_iterations=3\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "ee5472ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new  chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3mThought: I need to find the most recent financial information about coca-cola\n",
      "Action: information_retrival\n",
      "Action Input: coca-cola financials\u001b[0m\n",
      "\n",
      "Observation:\u001b[33;1m\u001b[1;3mRank: 1 | Content: Net income attributable to shareowners  \n",
      "\n",
      "of The Coca-Cola Company\n",
      "\n",
      "8,920\n",
      "\n",
      "7,747\n",
      "\n",
      "9,771\n",
      "\n",
      "9,542\n",
      "\n",
      "20\n",
      "\n",
      "15\n",
      "\n",
      "10\n",
      "\n",
      "5\n",
      "\n",
      "0\n",
      "\n",
      "-5\n",
      "\n",
      "-10\n",
      "\n",
      "16%\n",
      "\n",
      "16%\n",
      "\n",
      "6%\n",
      "\n",
      "2020\n",
      "\n",
      "2019\n",
      "\n",
      "2021\n",
      "\n",
      "2022\n",
      "\n",
      "(9%)\n",
      "\n",
      "20\n",
      "\n",
      "15\n",
      "\n",
      "10\n",
      "\n",
      "5\n",
      "\n",
      "0\n",
      "\n",
      "19%\n",
      "\n",
      "13%\n",
      "\n",
      "12%\n",
      "\n",
      "0%\n",
      "2020\n",
      "\n",
      "2019\n",
      "\n",
      "2021\n",
      "\n",
      "2022\n",
      "\n",
      "Organic Revenue Growth \n",
      "(Non-GAAP)1\n",
      "\n",
      "Comparable Currency Neutral Operating \n",
      "Income Growth (Non-GAAP)2\n",
      "\n",
      "Per Share Data\n",
      "\n",
      "Basic earnings per share\n",
      "\n",
      "$2.09\n",
      "\n",
      "$1.80\n",
      "\n",
      "$2.26\n",
      "\n",
      "$2.20\n",
      "\n",
      "Comparable Currency Neutral Diluted \n",
      "Earnings Per Share Growth (Non-GAAP)3\n",
      "\n",
      "Adjusted Free Cash Flow Conversion Ratio \n",
      "(Non-GAAP)4\n",
      "\n",
      "Diluted earnings per share\n",
      "\n",
      "Cash dividends\n",
      "\n",
      "Balance Sheet Data\n",
      "\n",
      "Total assets\n",
      "\n",
      "Long-term debt\n",
      "\n",
      "2.07\n",
      "\n",
      "1.60\n",
      "\n",
      "1.79\n",
      "\n",
      "1.64\n",
      "\n",
      "2.25\n",
      "\n",
      "1.68\n",
      "\n",
      "2.19\n",
      "\n",
      "1.76\n",
      "\n",
      "$86,381\n",
      "\n",
      "$87,296\n",
      "\n",
      "$94,354\n",
      "\n",
      "$ 92,763\n",
      "\n",
      "27,516\n",
      "\n",
      "40,125\n",
      "\n",
      "38,116\n",
      "\n",
      "36,377\n",
      "\n",
      "20\n",
      "\n",
      "15\n",
      "\n",
      "10\n",
      "\n",
      "5\n",
      "\n",
      "0\n",
      "\n",
      "-5\n",
      "\n",
      "17%\n",
      "\n",
      "17%\n",
      "\n",
      "9%\n",
      "\n",
      "2019\n",
      "\n",
      "2020\n",
      "\n",
      "(2%)\n",
      "\n",
      "Rank: 2 | Content: 40,125\n",
      "\n",
      "38,116\n",
      "\n",
      "36,377\n",
      "\n",
      "20\n",
      "\n",
      "15\n",
      "\n",
      "10\n",
      "\n",
      "5\n",
      "\n",
      "0\n",
      "\n",
      "-5\n",
      "\n",
      "17%\n",
      "\n",
      "17%\n",
      "\n",
      "9%\n",
      "\n",
      "2019\n",
      "\n",
      "2020\n",
      "\n",
      "(2%)\n",
      "\n",
      "2021\n",
      "\n",
      "2022\n",
      "\n",
      "120\n",
      "\n",
      "100\n",
      "\n",
      "80\n",
      "\n",
      "60\n",
      "\n",
      "40\n",
      "\n",
      "20\n",
      "\n",
      "0\n",
      "\n",
      "116%\n",
      "\n",
      "108%\n",
      "\n",
      "96%\n",
      "\n",
      "89%\n",
      "\n",
      "2019\n",
      "\n",
      "2020\n",
      "\n",
      "2021\n",
      "\n",
      "2022\n",
      "\n",
      "Note: See pages 72–74 for reconciliations of non-GAAP financial measures to our results as reported under accounting principles generally accepted \n",
      "in the United States (U.S. GAAP).\n",
      "\n",
      "1     Reported net operating revenues grew 9%, declined 11%, grew 17% \n",
      "and grew 11% for the years ended December 31, 2019, 2020, 2021 \n",
      "and 2022, respectively. \n",
      "\n",
      "3   Reported diluted earnings per share grew 38%, declined 13%, grew \n",
      "26% and declined 3% for the years ended December 31, 2019, 2020, \n",
      "2021 and 2022, respectively.\n",
      "\n",
      "2    Reported operating income grew 10%, declined 11%, grew 15% and \n",
      "grew 6% for the years ended December 31, 2019, 2020, 2021 and \n",
      "2022, respectively.\n",
      "\n",
      "4   Adjusted free cash flow conversion ratio = free cash flow adjusted \n",
      "\n",
      "for pension contributions divided by net income adjusted for \n",
      "noncash items impacting comparability.\n",
      "\n",
      "THE COCA-COLA COMPANY 2022 BUSINESS & SUSTAINABILITY REPORT\n",
      "\n",
      "17\n",
      "\n",
      " \n",
      "\f",
      "CONTENTS\n",
      "\n",
      "CEO MESSAGE\n",
      "\n",
      "EXECUTIVE SUMMARY\n",
      "\n",
      "OUR COMPANY\n",
      "\n",
      "WATER\n",
      "\n",
      "PORTFOLIO\n",
      "\n",
      "PACKAGING\n",
      "\n",
      "CLIMATE\n",
      "\n",
      "Contextual information sorted from most relevant to least relevant.\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3m I can now answer the question\n",
      "Final Answer: 9,771\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "result = agent_executor.run(\n",
    "    input=\"what were the net operating revenues of coca-cola in 2022\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6461d6d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
