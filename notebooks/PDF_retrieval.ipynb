{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "944b9159",
   "metadata": {},
   "source": [
    "# Belfius Alytics (Part 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65d16ff7",
   "metadata": {},
   "source": [
    "### Handle Imports:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1d32c11a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\MD726YR\\PycharmProjects\\eyalytics\n"
     ]
    }
   ],
   "source": [
    "# Move to root directory\n",
    "import os\n",
    "\n",
    "notebooks_dir = 'notebooks'\n",
    "if notebooks_dir in os.path.abspath(os.curdir):\n",
    "    while not os.path.abspath(os.curdir).endswith('notebooks'):\n",
    "        print(os.path.abspath(os.curdir))\n",
    "        os.chdir('..')\n",
    "    os.chdir('..')  # to get to root\n",
    "\n",
    "print(os.path.abspath(os.curdir))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e3f02e28",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Supress SSL verification (EY problem):\n",
    "import requests\n",
    "\n",
    "from requests.packages.urllib3.exceptions import InsecureRequestWarning\n",
    "\n",
    "# Suppress the warning from urllib3.\n",
    "requests.packages.urllib3.disable_warnings(category=InsecureRequestWarning)\n",
    "\n",
    "old_send = requests.Session.send\n",
    "\n",
    "def new_send(*args, **kwargs):\n",
    "    kwargs['verify'] = False\n",
    "    return old_send(*args, **kwargs)\n",
    "\n",
    "requests.Session.send = new_send"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "edcff8a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import relevant libraries for llm ochestration:\n",
    "from langchain import OpenAI, LLMChain, PromptTemplate\n",
    "from langchain.prompts import StringPromptTemplate\n",
    "from langchain.agents import (\n",
    "    AgentExecutor, LLMSingleActionAgent, AgentOutputParser, \n",
    "    AgentType, initialize_agent, Tool\n",
    ")\n",
    "from langchain.tools import BaseTool\n",
    "from langchain.callbacks import get_openai_callback\n",
    "from langchain.schema import AgentAction, AgentFinish"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "213a1e1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries for web scraping:\n",
    "import mimetypes\n",
    "import urllib.parse\n",
    "from bs4 import BeautifulSoup\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.chrome.options import Options \n",
    "from selenium.webdriver.common.by import By\n",
    "from PyPDF2 import PdfReader\n",
    "from io import BytesIO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "156b423c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Other imports:\n",
    "import re \n",
    "\n",
    "from typing import List, Dict, Optional, Union"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "96298428",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get API Key:\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "if not os.getenv(\"OPENAI_API_KEY\"):\n",
    "    raise KeyError(\n",
    "        \"You will need an OPENAI_API_KEY to use the LLM models in this notebook.\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16aa4ddc",
   "metadata": {},
   "source": [
    "Set up token counting to monitor costs:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a10ffec4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Update\n",
    "def count_tokens(agent, query):\n",
    "    with get_openai_callback() as cb:\n",
    "        result = agent(query)\n",
    "        print(f'Spent a total of {cb.total_tokens} tokens')\n",
    "\n",
    "    return result"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de4bb889",
   "metadata": {},
   "source": [
    "## Commence Agent Development:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12c3d5aa",
   "metadata": {},
   "source": [
    "#### Custom Tooling:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9a29a25",
   "metadata": {},
   "source": [
    "Start by developing tools for fetching urls and descriptions from duckduckgo. Once you have this, additionally, develop a url scraper that fetches all the downloadable links from a website.\n",
    "\n",
    "For more information about creating custom tooling check out: \n",
    "    \n",
    "https://github.com/pinecone-io/examples/blob/master/generation/langchain/handbook/07-langchain-tools.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7eac3017",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import mimetypes\n",
    "import urllib.parse\n",
    "from bs4 import BeautifulSoup\n",
    "from selenium import webdriver\n",
    "from typing import List, Dict, Optional\n",
    "\n",
    "\n",
    "def is_downloadable(url: str) -> bool:\n",
    "    \"\"\"\n",
    "    Check if a url is a downloadable link.\n",
    "    \n",
    "    Example:\n",
    "        is_downloadable(\n",
    "            'https://www.coca-colacompany.com/content/dam/journey/us/en/reports/coca-cola-business-and-sustainability-report-2022.pdf'\n",
    "        ) -> True\n",
    "    \"\"\"\n",
    "    mimetype, encoding = mimetypes.guess_type(url)\n",
    "    if mimetype and mimetype.startswith('application'):\n",
    "        return True\n",
    "\n",
    "    try:\n",
    "        h = requests.head(url, allow_redirects=True)\n",
    "        header = h.headers\n",
    "        content_type = header.get('content-type')\n",
    "        if content_type and 'application' in content_type.lower():\n",
    "            return True\n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred: {e}\")\n",
    "\n",
    "    return False\n",
    "\n",
    "\n",
    "def fetch_duckduckgo_results(query: str, num_results: int = 5) -> List[Dict[str, Union[str, bool, int]]]:\n",
    "    \"\"\"\n",
    "    Fetch search results from DuckDuckGo using Selenium and BeautifulSoup.\n",
    "    \n",
    "    Parameters:\n",
    "    - query (str): The search query string.\n",
    "    - num_results (int, optional): Maximum number of results to fetch. Defaults to 5.\n",
    "\n",
    "    Returns:\n",
    "    - list[dict]: Returns a list of dictionaries containing the following details about the search results:\n",
    "        * title (str): Title of the search result.\n",
    "        * description (str, optional): Description or snippet of the result.\n",
    "        * link (str, optional): Direct URL of the search result.\n",
    "        * downloadable (bool): Whether the link points to downloadable content.\n",
    "        * rank (int): Rank or position of the search result on the page.\n",
    "    \"\"\"\n",
    "    \n",
    "    chrome_options = webdriver.ChromeOptions()\n",
    "    chrome_options.add_argument(\"--headless\")\n",
    "    driver = webdriver.Chrome(options=chrome_options)\n",
    "    url = f\"https://duckduckgo.com/html/?q={query}\"\n",
    "    driver.get(url)\n",
    "    \n",
    "    soup = BeautifulSoup(driver.page_source, 'html.parser')\n",
    "    search_results = soup.find_all('div', class_='result__body')\n",
    "    \n",
    "    results = []\n",
    "    for rank, result in enumerate(search_results):\n",
    "        title = result.find('a', class_='result__a').get_text(strip=True) if result.find('a', class_='result__a') else None\n",
    "        description = result.find('a', class_='result__snippet').get_text(strip=True) if result.find('a', class_='result__snippet') else None\n",
    "        link = result.find('a', class_='result__url').get('href') if result.find('a', class_='result__url') else None\n",
    "        \n",
    "        if link:\n",
    "            actual_url_encoded = urllib.parse.parse_qs(\n",
    "                urllib.parse.urlparse(link).query\n",
    "            ).get(\"uddg\", [None])[0]\n",
    "            if actual_url_encoded:\n",
    "                final_link = urllib.parse.unquote(actual_url_encoded)\n",
    "            else:\n",
    "                final_link = None\n",
    "        else:\n",
    "            final_link = None\n",
    "        \n",
    "        results.append({\n",
    "            'title': title,\n",
    "            'description': description,\n",
    "            'link': final_link,\n",
    "            'downloadable': is_downloadable(final_link) if final_link else False,\n",
    "            'rank': rank,\n",
    "        })\n",
    "        \n",
    "        if len(results) >= num_results:\n",
    "            break\n",
    "    \n",
    "    driver.quit()\n",
    "    return results\n",
    "\n",
    "\n",
    "def extract_link_description(link: BeautifulSoup) -> str:\n",
    "    \"\"\"\n",
    "    Extract the most relevant description for a BeautifulSoup link element.\n",
    "    \n",
    "    The function uses a series of heuristics to determine the best description:\n",
    "    1. The link's text.\n",
    "    2. The 'alt' attribute of any child <img> tag.\n",
    "    3. The 'title' attribute of the link.\n",
    "    4. The link's href itself.\n",
    "    \n",
    "    Parameters:\n",
    "    - link (BeautifulSoup): The BeautifulSoup element representing the link (a-tag).\n",
    "    \n",
    "    Returns:\n",
    "    - str: A description extracted based on the heuristics.\n",
    "    \"\"\"\n",
    "    \n",
    "    description = link.string.strip() if link.string else None\n",
    "\n",
    "    if not description:\n",
    "        img_tag = link.find('img')\n",
    "        if img_tag and 'alt' in img_tag.attrs:\n",
    "            description = img_tag['alt'].strip()\n",
    "\n",
    "    if not description and 'title' in link.attrs:\n",
    "        description = link['title'].strip()\n",
    "\n",
    "    if not description:\n",
    "        description = link['href']\n",
    "\n",
    "    return description\n",
    "\n",
    "\n",
    "def extract_download_links_from_url(url: str) -> List[Dict[str, str]]:\n",
    "    \"\"\"\n",
    "    Scrape a given URL and extract links that are deemed downloadable.\n",
    "    \n",
    "    Parameters:\n",
    "    - url (str): The URL to scrape.\n",
    "    \n",
    "    Returns:\n",
    "    - list[dict]: A list of dictionaries with two keys:\n",
    "        * description (str): A description or title for the link.\n",
    "        * link (str): The actual URL of the link.\n",
    "    \"\"\"\n",
    "    \n",
    "    if is_downloadable(url):\n",
    "        return [{'description': 'Downloadable link.', 'link': url}]\n",
    "        \n",
    "    response = requests.get(url)\n",
    "    soup = BeautifulSoup(response.content, 'html.parser')\n",
    "    anchors = soup.find_all('a', href=True)\n",
    "\n",
    "    link_dict = {}\n",
    "\n",
    "    for anchor in anchors:\n",
    "        # Step 1: Resolve to absolute URL\n",
    "        relative_href = anchor['href']\n",
    "        absolute_href = urllib.parse.urljoin(url, relative_href)\n",
    "        \n",
    "        # Step 2: Strip fragments\n",
    "        main_url = urllib.parse.urldefrag(absolute_href).url\n",
    "\n",
    "        # Step 3: Check if downloadable\n",
    "        if is_downloadable(main_url):\n",
    "            description = extract_link_description(anchor)\n",
    "\n",
    "            # Step 4: Decide on description update\n",
    "            if main_url not in link_dict or len(description) > len(link_dict[main_url]['description']):\n",
    "                link_dict[main_url] = {'description': description, 'link': main_url}\n",
    "\n",
    "    return list(link_dict.values())\n",
    "\n",
    "\n",
    "def get_pdf_page_count(url: str) -> int:\n",
    "    try:\n",
    "        # Fetch the PDF content using requests\n",
    "        response = requests.get(url)\n",
    "        response.raise_for_status()  # Raises an HTTPError if the response returned an unsuccessful status code\n",
    "        \n",
    "        # Use BytesIO to convert the byte stream to a file-like object so it can be read by PyPDF2\n",
    "        with BytesIO(response.content) as pdf_data:\n",
    "            # Read the PDF\n",
    "            pdf_reader = PdfReader(pdf_data)\n",
    "            return len(pdf_reader.pages)\n",
    "    except requests.RequestException as e:\n",
    "        print(f\"Error fetching the PDF: {e}\")\n",
    "        return -1\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing the PDF: {e}\")\n",
    "        return -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "cca0f5a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'title': '2022 Business & Sustainability Report - The Coca-Cola Company', 'description': 'CLIMATE Our ability to deliver quality products requires a sustainable and secure supply of agricultural ingredients. In 2021, we launched our Principles for Sustainable Agriculture (PSA) to encourage and guide our suppliers to drive continuous improvement in sustainable farming practices.', 'link': 'https://www.coca-colacompany.com/reports/business-and-sustainability-report', 'downloadable': False, 'rank': 0}\n",
      "\n",
      "{'title': 'Sustainability - The Coca-Cola Company', 'description': \"Water Stewardship Water balance is giving back to nature and communities. We go beyond to improve water security where it's needed most. Explore In Our Products We provide high-quality products and cutting edge ingredients sourced sustainably and ethically. Explore Sustainable Agriculture\", 'link': 'https://www.coca-colacompany.com/sustainability', 'downloadable': False, 'rank': 1}\n",
      "\n",
      "{'title': 'Sustainability & Governance Resource Center - The Coca-Cola Company', 'description': 'L - R Alcohol Responsibility Animal Testing Animal Welfare Board Diversity Board Leadership Structure Board of Directors Child Labor Climate Community Impact Corporate Governance Deforestation Deposit Scheme Diversity, Equity & Inclusion Disaster Relief', 'link': 'https://www.coca-colacompany.com/sustainability-resource-center', 'downloadable': False, 'rank': 2}\n",
      "\n",
      "{'title': 'Investor Relations :: The Coca-Cola Company (KO)', 'description': 'Latest Financial Results Jul 26,2023• 6:55 AM EDT Q22023Quarterly Results Quarter Ended Jun 30,2023Earnings Release PDF Audio Earnings Webcast Margin Analysis Schedule PDF 10-Q PDF HTML XBRL ZIP XLS HTML Transcript PDF Audio MP3 dbAccess Global Consumer Conference Jun 8,2023• 5:00 am EDT View Event Transcript PDF Audio Webcast', 'link': 'http://investors.coca-colacompany.com/', 'downloadable': False, 'rank': 3}\n",
      "\n",
      "{'title': 'Sustainability :: The Coca-Cola Company (KO)', 'description': \"Sustainable Packaging Climate Policies, Practices &ReportsSustainabilityOur planet matters. We act in ways to create a more sustainable and better shared future. To make a difference in people's lives, communities and our planet by doing business the right way. ViewSustainabilitySocial Impact People matter.\", 'link': 'https://investors.coca-colacompany.com/sustainability', 'downloadable': False, 'rank': 4}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Test the tool.\n",
    "query = \"Coca-Cola sustainability report 2023\"\n",
    "results = fetch_duckduckgo_results(query, 5)\n",
    "for _result in results:\n",
    "    print(f\"{_result}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c308697",
   "metadata": {},
   "outputs": [],
   "source": [
    "for _result in results[:5]:\n",
    "    link = _result['link']\n",
    "    _results = extract_download_links_from_url(link)\n",
    "    print(f\"Scraping: {link}\\n{_results}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4becd126",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Testing the function\n",
    "url = \"https://www.coca-colacompany.com/content/dam/company/us/en/reports/coca-cola-business-and-sustainability-report-2022.pdf\"\n",
    "print(f\"The PDF has {get_pdf_page_count(url)} pages.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b3496fe",
   "metadata": {},
   "source": [
    "With the functions prepared, lets rap these in custom langchain tools:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "02baf0eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_search_results(search_results):\n",
    "    search_results.sort(key=lambda x: x['rank'])  # Sort by rank\n",
    "    formatted_results = [\n",
    "        \"Search Results (sorted based on page rank):\\n\"\n",
    "    ]\n",
    "\n",
    "    for entry in search_results:\n",
    "        formatted_results.append(\"URL: '{}'\\n\".format(entry['link']))\n",
    "        formatted_results.append(\"Downloadable: {}\\n\".format(\n",
    "            entry['downloadable']\n",
    "        ))\n",
    "        formatted_results.append(\"Description: {}; {}\\n\".format(\n",
    "            entry['title'], entry['description']))\n",
    "        formatted_results.append(\"\\n\\n\")\n",
    "\n",
    "    formatted_results.append(\n",
    "        \"\\nNote that when Downloadable is True, the url \" +\n",
    "        \"is a downloadable link and should not be scraped.\"\n",
    "    )\n",
    "    return \"\".join(formatted_results)\n",
    "\n",
    "\n",
    "def format_url_scrape_results(url, scrape_results):\n",
    "    formatted_results = [\n",
    "        f\"Downloadable links scraped from {url} (in no particular order):\\n\"]\n",
    "\n",
    "    for entry in scrape_results:\n",
    "        formatted_results.append(\"URL: {}\".format(entry['link']))\n",
    "        formatted_results.append(\"Description: {}\\n\".format(entry['description']))\n",
    "        formatted_results.append(\"\\n\")\n",
    "        \n",
    "    return \"\".join(formatted_results)\n",
    "    \n",
    "    \n",
    "class DDGoSearch(BaseTool):\n",
    "    \n",
    "    name = fetch_duckduckgo_results.__name__\n",
    "    description = \"\"\"\n",
    "        Fetch search results from DuckDuckGo.\n",
    "        \n",
    "        Elaborating, this tool will return a list of urls and their \n",
    "        accompanying duckduckgo descriptions. For each url a flag\n",
    "        indicating if the url is downloadable is outputed as well.\n",
    "    \"\"\"\n",
    "    \n",
    "    def _run(self, query: str) -> bool:\n",
    "        ddgo_results = fetch_duckduckgo_results(\n",
    "            query=query, \n",
    "            num_results=5,\n",
    "        )\n",
    "        return format_search_results(ddgo_results)\n",
    "        \n",
    "    \n",
    "    def _arun(self, query: str):\n",
    "        raise NotImplementedError(\n",
    "            f\"{self.__class__.__name__} does not currently support async run.\"\n",
    "        )\n",
    "    \n",
    "    \n",
    "class URLScraper(BaseTool):\n",
    "    \n",
    "    name = extract_download_links_from_url.__name__\n",
    "    description = \"\"\"\n",
    "        URL Scraper. Given a URL this tool \n",
    "        scrapes a webpage and returns all downloadable links, \n",
    "        along with their descriptions, appearing on that webpage.\n",
    "        Note this tool should be used on non-downloadable links.\n",
    "    \"\"\"\n",
    "    \n",
    "    def _run(self, url: str) -> bool:\n",
    "        scrape_results = extract_download_links_from_url(url.strip(\" '\\\"\"))\n",
    "        return format_url_scrape_results(url, scrape_results)\n",
    "    \n",
    "    def _arun(self, url: str):\n",
    "        raise NotImplementedError(\n",
    "            f\"{self.__class__.__name__} does not currently support async run.\"\n",
    "        )\n",
    "        \n",
    "\n",
    "class PDFPageCounter(BaseTool):\n",
    "    \n",
    "    name = get_pdf_page_count.__name__\n",
    "    description = \"\"\"\n",
    "        PDF page counter. Use to determine if a url\n",
    "        pointing to a pdf links to a summary or \n",
    "        a full document. \n",
    "    \"\"\"\n",
    "    \n",
    "    def _run(self, url: str) -> bool:\n",
    "        page_count = get_pdf_page_count(url.strip(\" '\\\"\"))\n",
    "        if page_count == -1: \n",
    "            return f\"URL: {url} | Error, page count could not be determined. Document may not be a pdf.\"\n",
    "        elif page_count < 20:\n",
    "            return f\"URL: {url} | Page Count: {page_count} | \" + \\\n",
    "                \"url is probably an executive summary and not a full report.\"\n",
    "        else:\n",
    "            return f\"URL: {url} | Page Count: {page_count} | \" + \\\n",
    "                \"url is significant in size indicating that it is probably a full report.\"\n",
    "        return \"URL: {pae}\"\n",
    "    \n",
    "    def _arun(self, url: str):\n",
    "        raise NotImplementedError(\n",
    "            f\"{self.__class__.__name__} does not currently support async run.\"\n",
    "        )\n",
    "        \n",
    "tools = [DDGoSearch(), URLScraper(), PDFPageCounter()]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abff0ab5",
   "metadata": {},
   "source": [
    "Now that we have functioning tools for URL retrival, let's build custom prompts and agents for our task:\n",
    "\n",
    "*For details about agents see: \n",
    "- https://www.pinecone.io/learn/series/langchain/langchain-agents/*\n",
    "- https://colab.research.google.com/drive/1ipuSd6Jnl9KMF39LbA1n6FDDx5HBntZd?usp=sharing#scrollTo=nBKP5V4Aifx6"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20fc74d7",
   "metadata": {},
   "source": [
    "#### Prompt Template:\n",
    "This instructs the agent on what to do. Generally, the template should incorporate:\n",
    "\n",
    "**`tools:`** which tools the agent has access and how and when to call them.\n",
    "\n",
    "**`intermediate_steps:`** These are tuples of previous (**`AgentAction`**, **`Observation`**) pairs. These are generally not passed directly to the model, but the prompt template formats them in a specific way.\n",
    "\n",
    "**`input:`** generic user input\n",
    "\n",
    "*WARNING:* Avoid changing these key names, as using varying key names can cause \n",
    "    downstream issues."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "fbd14808",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up the base template\n",
    "template = \"\"\"You are a web scraping agent. You have access to the following tools:\n",
    "\n",
    "{tools}\n",
    "\n",
    "Use the following format:\n",
    "\n",
    "Question: the input question you must answer\n",
    "Thought: you should always think about what to do\n",
    "Action: the action to take, should be one of [{tool_names}]\n",
    "Action Input: the input to the action\n",
    "Observation: the result of the action\n",
    "... (this Thought/Action/Action Input/Observation can repeat N times)\n",
    "Thought: I now know the final answer\n",
    "Final Answer: the final answer to the original input question\n",
    "\n",
    "Begin! Remember to answer as succinctly as possible when giving your final answer.\n",
    "\n",
    "Question: {input}\n",
    "{agent_scratchpad}\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ee92607b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up a prompt template which breaksup the intermediate_steps\n",
    "# into thoughts that are used to fill the agent_scratchpad, \n",
    "# tools, and tool_names in the base template:\n",
    "class CustomPromptTemplate(StringPromptTemplate):\n",
    "    # The template to use\n",
    "    template: str\n",
    "    # The list of tools available\n",
    "    tools: List[BaseTool or Tool]\n",
    "    \n",
    "    def format(self, **kwargs) -> str:\n",
    "        # Get the intermediate steps (AgentAction, Observation tuples)\n",
    "        # Format them in a particular way\n",
    "        intermediate_steps = kwargs.pop(\"intermediate_steps\")\n",
    "        thoughts = \"\"\n",
    "        for action, observation in intermediate_steps:\n",
    "            thoughts += action.log\n",
    "            thoughts += f\"\\nObservation: {observation}\\nThought: \"\n",
    "        # Set the agent_scratchpad variable to that value\n",
    "        kwargs[\"agent_scratchpad\"] = thoughts\n",
    "        # Create a tools variable from the list of tools provided\n",
    "        kwargs[\"tools\"] = \"\\n\".join([f\"{tool.name}: {tool.description}\" for tool in self.tools])\n",
    "        # Create a list of tool names for the tools provided\n",
    "        kwargs[\"tool_names\"] = \", \".join([tool.name for tool in self.tools])\n",
    "        return self.template.format(**kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e7c8af6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = CustomPromptTemplate(\n",
    "    template=template,\n",
    "    tools=tools,\n",
    "    # This omits the `agent_scratchpad`, `tools`, and `tool_names` variables because those are generated dynamically\n",
    "    # This includes the `intermediate_steps` variable because that is needed\n",
    "    input_variables=[\"input\", \"intermediate_steps\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f161a33",
   "metadata": {},
   "source": [
    "#### Custom Output Parser:\n",
    "The output parser is responsible for parsing the LLM output into AgentAction and AgentFinish. This usually depends heavily on the prompt used.\n",
    "\n",
    "This is where you can change the parsing to do retries, handle whitespace, etc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b8b89f44",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomOutputParser(AgentOutputParser):\n",
    "    \n",
    "    def parse(self, llm_output: str) -> Union[AgentAction, AgentFinish]:\n",
    "        # Check if agent should finish\n",
    "        if \"Final Answer:\" in llm_output:\n",
    "            return AgentFinish(\n",
    "                # Return values is generally always a dictionary with a single `output` key\n",
    "                # It is not recommended to try anything else at the moment :)\n",
    "                return_values={\"output\": llm_output.split(\"Final Answer:\")[-1].strip()},\n",
    "                log=llm_output,\n",
    "            )\n",
    "        # Parse out the action and action input\n",
    "        regex = r\"Action\\s*\\d*\\s*:(.*?)\\nAction\\s*\\d*\\s*Input\\s*\\d*\\s*:[\\s]*(.*)\"\n",
    "        match = re.search(regex, llm_output, re.DOTALL)\n",
    "        if not match:\n",
    "            raise ValueError(f\"Could not parse LLM output: `{llm_output}`\")\n",
    "        action = match.group(1).strip()\n",
    "        action_input = match.group(2)\n",
    "        # Return the action and action input\n",
    "        return AgentAction(tool=action, tool_input=action_input.strip(\" \").strip('\"'), log=llm_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "2d118385",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_parser = CustomOutputParser()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0233c3b",
   "metadata": {},
   "source": [
    "#### Agent Set-Up:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "fe6dccb6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\MD726YR\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\eyalytics-cpKgxviR-py3.8\\lib\\site-packages\\langchain\\llms\\openai.py:179: UserWarning: You are trying to use a chat model. This way of initializing it is no longer supported. Instead, please use: `from langchain.chat_models import ChatOpenAI`\n",
      "  warnings.warn(\n",
      "C:\\Users\\MD726YR\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\eyalytics-cpKgxviR-py3.8\\lib\\site-packages\\langchain\\llms\\openai.py:753: UserWarning: You are trying to use a chat model. This way of initializing it is no longer supported. Instead, please use: `from langchain.chat_models import ChatOpenAI`\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "llm = OpenAI(\n",
    "    temperature=0,  # measure of randomness/creativity\n",
    "    model_name='gpt-3.5-turbo'\n",
    ")\n",
    "\n",
    "# LLM chain consisting of the LLM and a prompt\n",
    "llm_chain = LLMChain(\n",
    "    llm=llm, \n",
    "    prompt=prompt  # Custom Prompt\n",
    ")\n",
    "\n",
    "tool_names = [tool.name for tool in tools]\n",
    "\n",
    "agent = LLMSingleActionAgent(\n",
    "    llm_chain=llm_chain, \n",
    "    output_parser=output_parser,  # Custom Output Parser\n",
    "    stop=[\"\\nObservation:\"],  # you want this to be whatever token you use in the prompt to denote the start of an Observation\n",
    "    allowed_tools=tool_names\n",
    ") "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9b12bc3",
   "metadata": {},
   "source": [
    "Set up an Agent Executor, which orchestrates an agent to decide which tools to call and in what order."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "327891a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "agent_executor = AgentExecutor.from_agent_and_tools(\n",
    "    agent=agent, \n",
    "    tools=tools, \n",
    "    verbose=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47ab2df8",
   "metadata": {},
   "source": [
    "**Define** the agent's goal/question and run the agent executor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ad9c5616",
   "metadata": {},
   "outputs": [],
   "source": [
    "search_template = \"\"\"\n",
    "    You are tasked with finding a downloadable URL link to the most recent FULL sustainability report of {company}. Please search the web for this link; checking years 2023, 2022, and2021 (in that order) until you find one. You may need the scrape {company}'s official site to find a downloadable link to a report.\n",
    "    \n",
    "    Note, the final output should (where available) be a downloadable url, specifying a path to the sustainability report. As soon as you find a downloadable report you may stop the search. For instance if you search for the 2023 report, and find a downloadable link for the company's FULL 2023 report, you should return this url. If based on a url's description, you think that a longer report may be found on some web-page, you can check that web-page for downloadable links. This may happen when a recent executive summary of a report is found from a search, but you believe that a FULL report may be available on a company's web-page. If neither the search not url scraping finds anything please continue your search with less recent dates. If you fail to find a full report feel free to return an empty url.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "774802e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "    You are tasked with finding a downloadable URL link to the most recent FULL sustainability report of Coca-Cola. Please search the web for this link; checking years 2023, 2022, and2021 (in that order) until you find one. You may need the scrape Coca-Cola's official site to find a downloadable link to a report.\n",
      "    \n",
      "    Note, the final output should (where available) be a downloadable url, specifying a path to the sustainability report. As soon as you find a downloadable report you may stop the search. For instance if you search for the 2023 report, and find a downloadable link for the company's FULL 2023 report, you should return this url. If based on a url's description, you think that a longer report may be found on some web-page, you can check that web-page for downloadable links. This may happen when a recent executive summary of a report is found from a search, but you believe that a FULL report may be available on a company's web-page. If neither the search not url scraping finds anything please continue your search with less recent dates. If you fail to find a full report feel free to return an empty url.\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new  chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3mThought: To find a downloadable URL link to the most recent FULL sustainability report of Coca-Cola, I should start by searching for the 2023 report. If I find a downloadable link for the FULL 2023 report, I can stop the search. If not, I should continue searching for the 2022 report, and then the 2021 report if necessary.\n",
      "\n",
      "Action: fetch_duckduckgo_results\n",
      "Action Input: \"Coca-Cola sustainability report 2023\"\u001b[0m\n",
      "\n",
      "Observation:\u001b[36;1m\u001b[1;3mSearch Results (sorted based on page rank):\n",
      "URL: 'https://www.coca-colacompany.com/reports/business-and-sustainability-report'\n",
      "Downloadable: False\n",
      "Description: 2022 Business & Sustainability Report - The Coca-Cola Company; CLIMATE Our ability to deliver quality products requires a sustainable and secure supply of agricultural ingredients. In 2021, we launched our Principles for Sustainable Agriculture (PSA) to encourage and guide our suppliers to drive continuous improvement in sustainable farming practices.\n",
      "\n",
      "\n",
      "URL: 'https://www.coca-colacompany.com/sustainability'\n",
      "Downloadable: False\n",
      "Description: Sustainability - The Coca-Cola Company; Water Stewardship Water balance is giving back to nature and communities. We go beyond to improve water security where it's needed most. Explore In Our Products We provide high-quality products and cutting edge ingredients sourced sustainably and ethically. Explore Sustainable Agriculture\n",
      "\n",
      "\n",
      "URL: 'https://www.coca-colacompany.com/sustainability-resource-center'\n",
      "Downloadable: False\n",
      "Description: Sustainability & Governance Resource Center - The Coca-Cola Company; L - R Alcohol Responsibility Animal Testing Animal Welfare Board Diversity Board Leadership Structure Board of Directors Child Labor Climate Community Impact Corporate Governance Deforestation Deposit Scheme Diversity, Equity & Inclusion Disaster Relief\n",
      "\n",
      "\n",
      "URL: 'http://investors.coca-colacompany.com/'\n",
      "Downloadable: False\n",
      "Description: Investor Relations :: The Coca-Cola Company (KO); Latest Financial Results Jul 26,2023• 6:55 AM EDT Q22023Quarterly Results Quarter Ended Jun 30,2023Earnings Release PDF Audio Earnings Webcast Margin Analysis Schedule PDF 10-Q PDF HTML XBRL ZIP XLS HTML Transcript PDF Audio MP3 dbAccess Global Consumer Conference Jun 8,2023• 5:00 am EDT View Event Transcript PDF Audio Webcast\n",
      "\n",
      "\n",
      "URL: 'https://investors.coca-colacompany.com/sustainability'\n",
      "Downloadable: False\n",
      "Description: Sustainability :: The Coca-Cola Company (KO); Sustainable Packaging Climate Policies, Practices &ReportsSustainabilityOur planet matters. We act in ways to create a more sustainable and better shared future. To make a difference in people's lives, communities and our planet by doing business the right way. ViewSustainabilitySocial Impact People matter.\n",
      "\n",
      "\n",
      "\n",
      "Note that when Downloadable is True, the url is a downloadable link and should not be scraped.\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3mBased on the search results for the 2023 report, none of the URLs are downloadable. I should continue searching for the 2022 report.\n",
      "\n",
      "Action: fetch_duckduckgo_results\n",
      "Action Input: \"Coca-Cola sustainability report 2022\"\u001b[0m\n",
      "\n",
      "Observation:\u001b[36;1m\u001b[1;3mSearch Results (sorted based on page rank):\n",
      "URL: 'https://www.coca-colacompany.com/reports/business-and-sustainability-report'\n",
      "Downloadable: False\n",
      "Description: 2022 Business & Sustainability Report - The Coca-Cola Company; Our Business &SustainabilityReportaims to provide a transparent look at our actions, progress and learnings. As a global company with operations in more than 200 countries and territories, we have a responsibility to help protect local water resources.\n",
      "\n",
      "\n",
      "URL: 'https://www.coca-colacompany.com/sustainability'\n",
      "Downloadable: False\n",
      "Description: Sustainability - The Coca-Cola Company; Water Stewardship Water balance is giving back to nature and communities. We go beyond to improve water security where it's needed most. Explore In Our Products We provide high-quality products and cutting edge ingredients sourced sustainably and ethically. Explore Sustainable Agriculture\n",
      "\n",
      "\n",
      "URL: 'https://www.coca-colacompany.com/content/dam/company/us/en/reports/coca-cola-business-and-sustainability-report-2022.pdf'\n",
      "Downloadable: True\n",
      "Description: PDFThe Coca-Cola Company; TheCoca-ColaCompany\n",
      "\n",
      "\n",
      "URL: 'https://investors.coca-colacompany.com/strategy/sustainability'\n",
      "Downloadable: False\n",
      "Description: Sustainability :: The Coca-Cola Company (KO); Overview Vision Growth StrategySustainabilityFinancialsSustainabilityOur planet matters. We act in ways to create a more sustainable and better shared future. To make a difference in people's lives, communities and our planet by doing business the right way. ViewSustainabilitySocial Impact People matter.\n",
      "\n",
      "\n",
      "URL: 'https://www.coca-colacompany.com/sustainability/water-stewardship'\n",
      "Downloadable: False\n",
      "Description: Water Stewardship - The Coca-Cola Company; Explore Community Programs to Support Access to Water & Sanitation More than 18.5 million people provided access to safe drinking water, sanitation and hygiene since 2010. Explore Water Replenishment We have replenished more than 100% of the water used in our finished beverages every year since 2015. Explore our2022Progress Timeline 2004 2004\n",
      "\n",
      "\n",
      "\n",
      "Note that when Downloadable is True, the url is a downloadable link and should not be scraped.\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3mBased on the search results for the 2022 report, I found a downloadable link for the FULL 2022 sustainability report of Coca-Cola. I can stop the search and return this url.\n",
      "\n",
      "Final Answer: 'https://www.coca-colacompany.com/content/dam/company/us/en/reports/coca-cola-business-and-sustainability-report-2022.pdf'\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# Start the agent - you can use the search template we devised before. \n",
    "example_company = \"Coca-Cola\"\n",
    "task = search_template.format(company=example_company)\n",
    "print(f\"{task}\\n\")\n",
    "result = agent_executor.run(\n",
    "    input=task\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f6c81e7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "celltoolbar": "Raw Cell Format",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
