{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "import os\n",
    "load_dotenv()\n",
    "\n",
    "openai_api_key = os.getenv('OPENAI_API_KEY', 'YourAPIKeyIfNotSet')\n",
    "pinecone_api_key = os.getenv('PINECONE_API_KEY', '')\n",
    "pinecone_env = os.getenv('PINECONE_ENV', '')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "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\n"
     ]
    }
   ],
   "source": [
    "print(openai_api_key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.document_loaders import PyPDFLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "loader = PyPDFLoader(\"./data/colruyt_annualreport.pdf\")\n",
    "pages = loader.load_and_split()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Document(page_content='Product\\nCircular products\\nBy 2030, all our products will comply with \\nthe principles of the circular economy.Buying socially responsibly\\nBy 2035 we will purchase all our products \\nand services in a socially responsible \\nmanner.Reducing environmental impact  \\nof our products\\nBy 2035 we will halve the environmental \\nimpact of the products we sell.\\nDue diligence\\nBy 2025, we will know the country and region of origin (and where possible also links  \\nin the chain) for our private-label products. By 2030, this will also apply to national brands  \\nand indirect purchases. By 2027, we will have fully integrated due diligence into  \\nour business processes.Circular business models\\nWe are introducing circular business models \\ninto our (non-food) retail activities.Water footprint\\nBy 2025, 70% of our products  \\nfrom high-water-risk regions will meet  \\na water standard.Living standards\\nBy 2030, we will close the living wage and \\nliving income gap for our top five high-risk \\ncommodities. Packaging\\nBy 2030, all packaging in our stores will be \\nrecyclable or reusable.Climate change\\nBy 2027, 77% of our suppliers  \\n(by purchase figures) will have  \\nscience-based climate plans. Inclusive business practices\\nBy 2030, we will integrate inclusive business \\npractices in our key private-label chains.Food loss and food waste\\nEvery year we sell at least 97,4% of our fresh \\nproduce. By 2025, at least 40% of unsold \\nproducts that are still consumable will serve \\nfor human or animal consumption.Protection and restoration of ecosystems\\nBy 2030, we will eliminate deforestation and \\nland use conversion for products from  \\nhigh-risk chains.Human rights\\nWe promote human rights by actively \\nidentifying and remedying human right \\nviolations.\\nSustainable sourcing\\nBy 2030, our environmental, social and animal welfare objectives will be fully integrated into \\nour commercial chains.\\nINTRO  |  Word from the Chairman • Who are we? • Our strategy • Our vision on sustainability • Management report • Key figures7 objectives for the future  \\nand 27 sub-objectives  \\nto achieve them \\nWe have recently sharpened our sustainability strategy with \\nseven objectives. These respond to the most important \\nsustainability challenges facing us and the material \\nsustainability topics. To efficiently achieve these objectives, \\nwe classify them according to our three drivers: product, \\ninfrastructure and people.\\nThe environment and society are the common \\nthread running through our objectives:\\n•  In the ecological area, we intend to reduce our \\nenvironmental footprint as much as possible and \\npromote the circularity of raw materials, materials and \\nproducts. Our products are responsible for 95% of our \\nenvironmental impact. So we can make a big difference \\nhere.\\n•  In the social area, we want to make a positive contribution \\nby focusing on safeguarding human rights in the chain, \\nactively promoting balanced and sustainable lifestyles and \\nsupporting target groups in a vulnerable context.\\nWe consciously set objectives for the entire supply chain: \\nfrom the sourcing of raw materials, through our own \\nretail activities, to our customers. We hope that our new \\nobjectives will also inspire others and are convinced that \\ncollaboration is the key to creating a lasting positive impact.\\nTo concretely realise our seven overarching objectives, \\nwe have formulated 27 sub-objectives. At the time of \\npublication of this annual report, these (sub-)objectives are \\nstill new. Because we want to be transparent, we already \\nshare them here. We have already incorporated a number \\nof them into our sustainability reporting. From next year, \\nwe will integrate all (sub-)objectives in our reporting and \\ncommunicate clearly about our progress.\\n22', metadata={'source': './data/colruyt_annualreport.pdf', 'page': 21})"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pages[22]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jb_vandeneynde/.pyenv/versions/3.8.12/envs/llm_esg_env/lib/python3.8/site-packages/pinecone/index.py:4: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from tqdm.autonotebook import tqdm\n"
     ]
    }
   ],
   "source": [
    "from langchain.embeddings import OpenAIEmbeddings\n",
    "from langchain.vectorstores import Pinecone\n",
    "import pinecone"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings = OpenAIEmbeddings(openai_api_key=openai_api_key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "pinecone.init(\n",
    "    api_key=pinecone_api_key,\n",
    "    environment=pinecone_env\n",
    ")\n",
    "index_name = 'esg-kpi'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Retrying langchain.embeddings.openai.embed_with_retry.<locals>._embed_with_retry in 4.0 seconds as it raised RateLimitError: Rate limit reached for default-text-embedding-ada-002 in organization org-VjtZ9nCm3OcJrNOPIzN5eMIo on requests per min. Limit: 3 / min. Please try again in 20s. Contact us through our help center at help.openai.com if you continue to have issues. Please add a payment method to your account to increase your rate limit. Visit https://platform.openai.com/account/billing to add a payment method..\n",
      "Retrying langchain.embeddings.openai.embed_with_retry.<locals>._embed_with_retry in 4.0 seconds as it raised RateLimitError: Rate limit reached for default-text-embedding-ada-002 in organization org-VjtZ9nCm3OcJrNOPIzN5eMIo on requests per min. Limit: 3 / min. Please try again in 20s. Contact us through our help center at help.openai.com if you continue to have issues. Please add a payment method to your account to increase your rate limit. Visit https://platform.openai.com/account/billing to add a payment method..\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[29], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m docsearch \u001b[39m=\u001b[39m Pinecone\u001b[39m.\u001b[39;49mfrom_documents(pages, embeddings, index_name\u001b[39m=\u001b[39;49mindex_name)\n",
      "File \u001b[0;32m~/.pyenv/versions/3.8.12/envs/llm_esg_env/lib/python3.8/site-packages/langchain/vectorstores/base.py:420\u001b[0m, in \u001b[0;36mVectorStore.from_documents\u001b[0;34m(cls, documents, embedding, **kwargs)\u001b[0m\n\u001b[1;32m    418\u001b[0m texts \u001b[39m=\u001b[39m [d\u001b[39m.\u001b[39mpage_content \u001b[39mfor\u001b[39;00m d \u001b[39min\u001b[39;00m documents]\n\u001b[1;32m    419\u001b[0m metadatas \u001b[39m=\u001b[39m [d\u001b[39m.\u001b[39mmetadata \u001b[39mfor\u001b[39;00m d \u001b[39min\u001b[39;00m documents]\n\u001b[0;32m--> 420\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mcls\u001b[39;49m\u001b[39m.\u001b[39;49mfrom_texts(texts, embedding, metadatas\u001b[39m=\u001b[39;49mmetadatas, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/.pyenv/versions/3.8.12/envs/llm_esg_env/lib/python3.8/site-packages/langchain/vectorstores/pinecone.py:346\u001b[0m, in \u001b[0;36mPinecone.from_texts\u001b[0;34m(cls, texts, embedding, metadatas, ids, batch_size, text_key, index_name, namespace, upsert_kwargs, **kwargs)\u001b[0m\n\u001b[1;32m    344\u001b[0m     ids_batch \u001b[39m=\u001b[39m [\u001b[39mstr\u001b[39m(uuid\u001b[39m.\u001b[39muuid4()) \u001b[39mfor\u001b[39;00m n \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(i, i_end)]\n\u001b[1;32m    345\u001b[0m \u001b[39m# create embeddings\u001b[39;00m\n\u001b[0;32m--> 346\u001b[0m embeds \u001b[39m=\u001b[39m embedding\u001b[39m.\u001b[39;49membed_documents(lines_batch)\n\u001b[1;32m    347\u001b[0m \u001b[39m# prep metadata and upsert batch\u001b[39;00m\n\u001b[1;32m    348\u001b[0m \u001b[39mif\u001b[39;00m metadatas:\n",
      "File \u001b[0;32m~/.pyenv/versions/3.8.12/envs/llm_esg_env/lib/python3.8/site-packages/langchain/embeddings/openai.py:472\u001b[0m, in \u001b[0;36mOpenAIEmbeddings.embed_documents\u001b[0;34m(self, texts, chunk_size)\u001b[0m\n\u001b[1;32m    460\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"Call out to OpenAI's embedding endpoint for embedding search docs.\u001b[39;00m\n\u001b[1;32m    461\u001b[0m \n\u001b[1;32m    462\u001b[0m \u001b[39mArgs:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    468\u001b[0m \u001b[39m    List of embeddings, one for each text.\u001b[39;00m\n\u001b[1;32m    469\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    470\u001b[0m \u001b[39m# NOTE: to keep things simple, we assume the list may contain texts longer\u001b[39;00m\n\u001b[1;32m    471\u001b[0m \u001b[39m#       than the maximum context and use length-safe embedding function.\u001b[39;00m\n\u001b[0;32m--> 472\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_get_len_safe_embeddings(texts, engine\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdeployment)\n",
      "File \u001b[0;32m~/.pyenv/versions/3.8.12/envs/llm_esg_env/lib/python3.8/site-packages/langchain/embeddings/openai.py:358\u001b[0m, in \u001b[0;36mOpenAIEmbeddings._get_len_safe_embeddings\u001b[0;34m(self, texts, engine, chunk_size)\u001b[0m\n\u001b[1;32m    355\u001b[0m     _iter \u001b[39m=\u001b[39m \u001b[39mrange\u001b[39m(\u001b[39m0\u001b[39m, \u001b[39mlen\u001b[39m(tokens), _chunk_size)\n\u001b[1;32m    357\u001b[0m \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m _iter:\n\u001b[0;32m--> 358\u001b[0m     response \u001b[39m=\u001b[39m embed_with_retry(\n\u001b[1;32m    359\u001b[0m         \u001b[39mself\u001b[39;49m,\n\u001b[1;32m    360\u001b[0m         \u001b[39minput\u001b[39;49m\u001b[39m=\u001b[39;49mtokens[i : i \u001b[39m+\u001b[39;49m _chunk_size],\n\u001b[1;32m    361\u001b[0m         \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_invocation_params,\n\u001b[1;32m    362\u001b[0m     )\n\u001b[1;32m    363\u001b[0m     batched_embeddings \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m [r[\u001b[39m\"\u001b[39m\u001b[39membedding\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39mfor\u001b[39;00m r \u001b[39min\u001b[39;00m response[\u001b[39m\"\u001b[39m\u001b[39mdata\u001b[39m\u001b[39m\"\u001b[39m]]\n\u001b[1;32m    365\u001b[0m results: List[List[List[\u001b[39mfloat\u001b[39m]]] \u001b[39m=\u001b[39m [[] \u001b[39mfor\u001b[39;00m _ \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(\u001b[39mlen\u001b[39m(texts))]\n",
      "File \u001b[0;32m~/.pyenv/versions/3.8.12/envs/llm_esg_env/lib/python3.8/site-packages/langchain/embeddings/openai.py:107\u001b[0m, in \u001b[0;36membed_with_retry\u001b[0;34m(embeddings, **kwargs)\u001b[0m\n\u001b[1;32m    104\u001b[0m     response \u001b[39m=\u001b[39m embeddings\u001b[39m.\u001b[39mclient\u001b[39m.\u001b[39mcreate(\u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[1;32m    105\u001b[0m     \u001b[39mreturn\u001b[39;00m _check_response(response)\n\u001b[0;32m--> 107\u001b[0m \u001b[39mreturn\u001b[39;00m _embed_with_retry(\u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/.pyenv/versions/3.8.12/envs/llm_esg_env/lib/python3.8/site-packages/tenacity/__init__.py:289\u001b[0m, in \u001b[0;36mBaseRetrying.wraps.<locals>.wrapped_f\u001b[0;34m(*args, **kw)\u001b[0m\n\u001b[1;32m    287\u001b[0m \u001b[39m@functools\u001b[39m\u001b[39m.\u001b[39mwraps(f)\n\u001b[1;32m    288\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mwrapped_f\u001b[39m(\u001b[39m*\u001b[39margs: t\u001b[39m.\u001b[39mAny, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkw: t\u001b[39m.\u001b[39mAny) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m t\u001b[39m.\u001b[39mAny:\n\u001b[0;32m--> 289\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m(f, \u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkw)\n",
      "File \u001b[0;32m~/.pyenv/versions/3.8.12/envs/llm_esg_env/lib/python3.8/site-packages/tenacity/__init__.py:389\u001b[0m, in \u001b[0;36mRetrying.__call__\u001b[0;34m(self, fn, *args, **kwargs)\u001b[0m\n\u001b[1;32m    387\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39misinstance\u001b[39m(do, DoSleep):\n\u001b[1;32m    388\u001b[0m     retry_state\u001b[39m.\u001b[39mprepare_for_next_attempt()\n\u001b[0;32m--> 389\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49msleep(do)\n\u001b[1;32m    390\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    391\u001b[0m     \u001b[39mreturn\u001b[39;00m do\n",
      "File \u001b[0;32m~/.pyenv/versions/3.8.12/envs/llm_esg_env/lib/python3.8/site-packages/tenacity/nap.py:31\u001b[0m, in \u001b[0;36msleep\u001b[0;34m(seconds)\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39msleep\u001b[39m(seconds: \u001b[39mfloat\u001b[39m) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m     26\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m     27\u001b[0m \u001b[39m    Sleep strategy that delays execution for a given number of seconds.\u001b[39;00m\n\u001b[1;32m     28\u001b[0m \n\u001b[1;32m     29\u001b[0m \u001b[39m    This is the default strategy, and may be mocked out for unit testing.\u001b[39;00m\n\u001b[1;32m     30\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m---> 31\u001b[0m     time\u001b[39m.\u001b[39;49msleep(seconds)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "docsearch = Pinecone.from_documents(pages, embeddings, index_name=index_name)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.12 64-bit ('llm_esg_env')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "b99c5373b61ce2ad3b538d3e8d82502ab7801c6feda23817c805afcebb135a2e"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
